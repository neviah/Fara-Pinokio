# ğŸ¤– Fara-7B Computer Use Agent - Gradio Interface

A beautiful web interface for Microsoft's Fara-7B, the efficient 7B parameter agentic model designed for computer use and web automation.

![Fara-7B Interface](https://img.shields.io/badge/Fara--7B-Computer%20Use%20Agent-blue) ![Gradio](https://img.shields.io/badge/Gradio-Interface-orange) ![Pinokio](https://img.shields.io/badge/Pinokio-Compatible-green)

## âš ï¸ **IMPORTANT: You Must Run Fara-7B Locally**

**This interface requires the Fara-7B model to work.** You cannot use OpenAI's ChatGPT or other cloud LLMs.

**You have 3 options to run Fara-7B:**

1. **LM Studio** (Easiest - Recommended) â­ - User-friendly GUI, no command line needed
2. **VLLM** (Advanced) - Command line setup for power users
3. **Azure Foundry** (Cloud) - Deploy Fara-7B on Azure (paid)

See the **[Configuration](#ï¸-configuration)** section below for detailed setup instructions.

---

## ğŸŒŸ Features

- ğŸ¯ **Easy-to-use Gradio Interface**: Beautiful web UI for interacting with Fara-7B
- ğŸ¤– **Microsoft's Fara-7B**: State-of-the-art 7B parameter computer use agent  
- ğŸ  **Run Locally**: Complete privacy with on-device model hosting
- ğŸ“Š **Task Monitoring**: Real-time progress tracking
- ğŸ¨ **Modern Design**: Responsive interface with dark/light theme support
- ğŸš€ **Pinokio Compatible**: One-click installation and deployment
- ğŸ”’ **Privacy-First**: All processing happens on your machine

## ğŸ¬ What Fara-7B Can Do

Fara-7B can automate a wide variety of web tasks:

- ğŸ” **Search & Research**: Find information and summarize results
- ğŸ“ **Form Filling**: Complete forms and manage accounts
- ğŸ« **Booking Services**: Book travel, hotels, movie tickets, restaurants
- ğŸ›’ **Shopping**: Compare prices, add items to cart, checkout
- ğŸ’¼ **Job Hunting**: Find job postings and real estate listings
- ğŸ“Š **Data Collection**: Extract information from websites
- ğŸ—‚ï¸ **Account Management**: Login, navigate, and manage web accounts

---

## ğŸš€ Quick Start with Pinokio

### Step 1: Install the Interface

1. **Install Pinokio** from [pinokio.computer](https://pinokio.computer)

2. **Add this repository** to Pinokio:
   ```
   https://github.com/neviah/Fara-Pinokio
   ```

3. **Click Install** - Pinokio will automatically:
   - Set up Python virtual environment
   - Install all dependencies (Gradio, Playwright, etc.)
   - Download required browser automation tools
   - Create the Gradio interface

4. **Click Start** to launch the interface

### Step 2: Set Up Fara-7B Model Server

**âš ï¸ REQUIRED**: The interface alone won't work. You must also run the Fara-7B model using one of the methods below.

---

## âš™ï¸ Configuration

### Option 1: LM Studio (Recommended - Easiest) â­

**LM Studio is the EASIEST way to run Fara-7B locally!** No command line knowledge needed.

#### Why LM Studio?
- âœ… **User-friendly GUI** - No terminal commands required
- âœ… **One-click model download** - Browse and download models easily
- âœ… **Auto GPU detection** - Automatically uses your GPU if available
- âœ… **Built-in quantization** - Choose FP16, INT8, or INT4 for your VRAM
- âœ… **OpenAI-compatible API** - Works seamlessly with this interface

#### Setup Steps:

1. **Download and Install [LM Studio](https://lmstudio.ai/)**

2. **Download Fara-7B Model**:
   - Open LM Studio
   - Click the "ğŸ” Discover" tab (search icon)
   - Search for: `microsoft/Fara-7B` or `Fara-7B`
   - Choose a version based on your GPU VRAM:
     - **FP16** - Best quality, needs 12-14GB VRAM
     - **INT8** (Q8) - Good quality, needs 8GB VRAM
     - **INT4** (Q4_K_M) - Lower quality, needs 4-6GB VRAM
   - Click **Download**

3. **Start the Local Server**:
   - Click the "ğŸ’» Local Server" tab in LM Studio
   - Select the `Fara-7B` model you just downloaded
   - Click **"Start Server"**
   - Server starts on port `1234` (default)
   - âš ï¸ **Keep LM Studio running** while using the interface

4. **Configure This Interface**:
   - In the Gradio interface, click the **"âš™ï¸ Configuration"** tab
   - Enter:
     - **Model Endpoint**: `http://localhost:1234/v1`
     - **API Key**: `lm-studio` (any value works for local)
   - Click **"ğŸ’¾ Save Configuration"**

5. **Start Automating!** âœ…
   - Go to the **"ğŸš€ Run Tasks"** tab
   - Enter a task like: "Find an Xbox controller on Amazon"
   - Click **"Run Task"**
   - Watch Fara-7B work!

---

### Option 2: VLLM (Advanced - Command Line)

**For advanced users comfortable with the command line.**

#### Setup Steps:

1. **Install VLLM**:
   ```bash
   pip install vllm
   ```

2. **Start the Fara-7B Server**:
   ```bash
   vllm serve microsoft/Fara-7B --port 5000 --dtype auto
   ```
   - First run will download the model (~14GB)
   - Auto-detects GPU and uses FP16 if available
   - âš ï¸ **Keep this terminal open** while using the interface

3. **Configure This Interface**:
   - **Model Endpoint**: `http://localhost:5000/v1`
   - **API Key**: (leave empty for local)
   - Click **"ğŸ’¾ Save Configuration"**

---

### Option 3: Azure Foundry (Cloud - Paid)

**Deploy Fara-7B on Microsoft Azure for cloud-based inference.**

#### Setup Steps:

1. **Deploy Fara-7B** on [Azure AI Foundry](https://ai.azure.com/explore/models/Fara-7B/version/2/registry/azureml-msr)

2. **Get your endpoint details** from the Azure deployment page

3. **Configure This Interface**:
   - **Model Endpoint**: `https://your-endpoint.inference.ml.azure.com/v1`
   - **API Key**: Your Azure API key
   - Click **"ğŸ’¾ Save Configuration"**

---

## âŒ What WON'T Work

**This interface will NOT work with:**
- âŒ OpenAI ChatGPT API (`https://api.openai.com`)
- âŒ Anthropic Claude API
- âŒ Google Gemini API
- âŒ Any other cloud LLM service

**Why?** Fara-7B is a specialized model for computer use and web automation. It requires specific training and architecture that generic chat models don't have.

---

## ğŸ–¥ï¸ Interface Guide

### Main Interface Tabs

1. **ğŸš€ Run Tasks**: Main interface for running automation tasks
   - Enter task description
   - Monitor real-time progress
   - View results and actions taken

2. **âš™ï¸ Configuration**: Set up your Fara-7B model server
   - Configure LM Studio, VLLM, or Azure endpoint
   - Test connection
   - View setup instructions

3. **â„¹ï¸ About**: Learn about Fara-7B and the interface

### Example Tasks

Try these example tasks to get started:

- `"How many pages does Wikipedia have?"`
- `"Search for the weather in New York City"`
- `"Find the latest iPhone price on Apple's website"`
- `"Search for job openings for Python developers in Seattle"`
- `"Find a hotel in Paris for next month"`

---

## ğŸ¯ How It Works

1. **Visual Understanding**: Fara-7B takes screenshots of web pages and understands the visual layout

2. **Action Planning**: The model decides what actions to take (click, type, scroll, navigate)

3. **Coordinate Prediction**: Actions are executed at precise coordinates on the page

4. **Task Completion**: The agent continues until the task is completed or the maximum rounds are reached

---

## ğŸ“‹ System Requirements

### For the Gradio Interface:
- **Python**: 3.8 or higher
- **Memory**: 4GB RAM minimum
- **Storage**: 5GB free space for dependencies
- **Internet**: For downloading dependencies and web browsing

### For Running Fara-7B Locally (LM Studio or VLLM):

#### **Minimum VRAM** (4-6 GB)
- Supports quantized inference (INT4)
- Slower performance, good for testing
- **Example GPUs**: GTX 1660 Ti, RTX 3050, RTX 2060

#### **Recommended VRAM** (8-12 GB) â­
- INT8 or FP16 precision
- Smooth inference performance
- **Example GPUs**: RTX 3060 12GB, RTX 4060 Ti, RTX 3080 10GB

#### **Optimal VRAM** (16+ GB)
- Full FP16 precision with large contexts
- Fast inference
- **Example GPUs**: RTX 4080, RTX 4090, RTX A5000, A6000

#### **CPU Fallback** (No GPU)
- LM Studio and VLLM can run on CPU only
- **Very slow** (10-30x slower than GPU)
- Requires 16GB+ system RAM
- Functional for testing but not recommended for regular use

### Other Recommended Specs:
- **Memory**: 16GB+ RAM (32GB for CPU-only mode)
- **CPU**: Multi-core processor (8+ cores recommended)
- **Storage**: 20GB free (5GB interface + 14GB model weights)
- **Internet**: Stable broadband for model download and web browsing

---

## ğŸ› ï¸ Troubleshooting

### "Configuration Error - Please configure your model endpoint"
- **Cause**: You haven't set up a Fara-7B model server yet
- **Solution**: Follow the [Configuration](#ï¸-configuration) section above to set up LM Studio, VLLM, or Azure

### "Connection Error - Could not connect to endpoint"
- **Cause**: The model server isn't running
- **Solution**:
  - **LM Studio**: Make sure you clicked "Start Server" and it shows "Running"
  - **VLLM**: Check that the `vllm serve` command is still running in your terminal
  - **Azure**: Verify your endpoint URL and API key are correct

### "HTTP Error 400 - invalid model ID"
- **Cause**: You're using an OpenAI/ChatGPT endpoint instead of Fara-7B
- **Solution**: You MUST use Fara-7B. See the [Configuration](#ï¸-configuration) section to set up LM Studio or VLLM

### "Failed to install Playwright browsers"
- Run manually: `python -m playwright install`
- Check your internet connection
- Try running with admin/sudo privileges

### Model is very slow
- **Check GPU usage**: Make sure LM Studio/VLLM is using your GPU
- **Try quantization**: Use INT8 or INT4 models in LM Studio for faster inference
- **Check VRAM**: If you're running out of VRAM, use a smaller quantized model

### Getting Help

- ğŸ“– [Official Fara Documentation](https://github.com/microsoft/fara)
- ğŸ’¬ [Pinokio Discord](https://discord.gg/pinokio)
- ğŸ› [Report Issues](https://github.com/neviah/Fara-Pinokio/issues)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

The underlying Fara-7B model is licensed under Microsoft's terms. See the [official repository](https://github.com/microsoft/fara) for details.

## ğŸ™ Acknowledgments

- **Microsoft Research** for developing the amazing Fara-7B model
- **Gradio Team** for the excellent web interface framework
- **Pinokio Community** for the one-click deployment platform
- **LM Studio** for making local LLM hosting accessible to everyone

## ğŸ“Š Performance Notes

- **Speed**: Fara-7B averages ~16 steps per task vs ~41 for comparable models
- **Efficiency**: 7B parameters vs much larger competing agents
- **Accuracy**: State-of-the-art performance in its size class
- **Privacy**: Can run entirely on-device with local hosting

---

**Ready to automate your web tasks? Install Pinokio and set up LM Studio today!** ğŸš€
